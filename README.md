# Transformer-Based-Transform-Coding
## About
An **unofficial pytorch implementation** of ICLR2022 paper *"TRANSFORMER-BASED TRANSFORM CODING"*.

The project is based on [CompressAI 1.2.0](https://github.com/InterDigitalInc/CompressAI/), only the **"SwinT-Hyperprior(small)"** was reproduced.

I'm not sure all the details are following the original paper, the demo is only trained with MSE Loss, lambda=0.01, about 70k steps.

## Demo

**kodim01.png**

![kodim01.png](./images/kodim01.png)

**codec.png**

![codec.png](./images/codec.png)
