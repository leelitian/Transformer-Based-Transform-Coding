# Transformer-Based-Transform-Coding
An unofficial pytorch implementation of ICLR2022 paper "TRANSFORMER-BASED TRANSFORM CODING".

The project is based on CompressAI 1.2.0, only the "SwinT-Hyperprior(small)" was reproduced.

I'm not sure all the details are folowing the original paper, the demo is only trained with MSE Loss, lambda=0.01, about 70k steps.

**kodim01.png**

![kodim01.png](./images/kodim01.png)

**codec.png**

![codec.png](./images/codec.png)
